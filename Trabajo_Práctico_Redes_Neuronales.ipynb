{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_ztp3K9hj-Q"
      },
      "source": [
        "La red neuronal que armamos no cuenta con capas intermedias o ocultas. Solo tiene una capa de entrada, basada en un dataset descargado de Kaggle que contiene. Esta contiene atributos como tamaño, peso, dulzura, crujiente y jugosidad. La salida de la red intenta predecir tres clases no excluyentes para cada fruta: si es \"dulce\", \"jugosa\" y/o \"crujiente\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sLmz_6bShrZ1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bxsAbgw7jRT-"
      },
      "outputs": [],
      "source": [
        "#Utilizamos una función de activación sigmoide en la salida, para la clasificación binaria de cada clase.\n",
        "#La función sigmoide se usa como función de activación en la capa de salida, generando valores entre 0 y 1.\n",
        "def sigmoid(x):\n",
        "    x = np.clip(x, -500, 500)\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "#Fuencion derivada de la sigmoide\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "#Funciones de calculo y error\n",
        "def mean_squared_error(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ysM-xLRilAz_"
      },
      "outputs": [],
      "source": [
        "#Inicialización de pesos y bias de forma aleatoria\n",
        "def initialize_weights(input_size, output_size):\n",
        "    weights = np.random.randn(input_size, output_size) * np.sqrt(2. / input_size)\n",
        "    bias = np.zeros((1, output_size))\n",
        "    return weights, bias\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "osFDZSYAlcHS"
      },
      "outputs": [],
      "source": [
        "#Forward Pass\n",
        "#Aca calculo la salida de la red aplicando la función sigmoide después de multiplicar las entradas por los pesos y sumar el bias.\n",
        "def forward_pass(X, weights, bias):\n",
        "    z = np.dot(X, weights) + bias\n",
        "    return sigmoid(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GE0Qk6aelpOJ"
      },
      "outputs": [],
      "source": [
        "#Backpropagation\n",
        "#Ajusta los pesos y bias basándose en el error, utilizando la derivada de la función de activación.\n",
        "def backpropagation(X, y, output, weights, bias, learning_rate):\n",
        "    error = output - y\n",
        "    gradient = error * sigmoid_derivative(output)\n",
        "    d_weights = np.dot(X.T, gradient) / X.shape[0]\n",
        "    d_bias = np.sum(gradient, axis=0, keepdims=True) / X.shape[0]\n",
        "    weights -= learning_rate * d_weights\n",
        "    bias -= learning_rate * d_bias\n",
        "    return weights, bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zzADNTlDlwvh"
      },
      "outputs": [],
      "source": [
        "#Entrenamiento\n",
        "#Esto lo que hace es itera en varias épocas (ciclos de entrenamiento),\n",
        "#ajustando los pesos y bias en cada ciclo para minimizar el error.\n",
        "def train(X, y, input_size, output_size, epochs, learning_rate):\n",
        "    weights, bias = initialize_weights(input_size, output_size)\n",
        "    for epoch in range(epochs):\n",
        "        output = forward_pass(X, weights, bias)\n",
        "        loss = mean_squared_error(y, output)\n",
        "        weights, bias = backpropagation(X, y, output, weights, bias, learning_rate)\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "    return weights, bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9maQlSSJl2ge"
      },
      "outputs": [],
      "source": [
        "#Predicción\n",
        "#Al finalizar el entrenamiento, genera predicciones usando la función de activación en la capa de salida.\n",
        "#Las predicciones se redondean para obtener valores binarios (0 o 1).\n",
        "def predict(X, weights, bias):\n",
        "    output = forward_pass(X, weights, bias)\n",
        "    return (output > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lHYrir8zl4ey"
      },
      "outputs": [],
      "source": [
        "#Importo el dataset\n",
        "#Escogemos solo las columnas Size, Weight, Sweetness, Crunchiness, y Juiciness\n",
        "#que son las características de cada fruta en este caso.\n",
        "#Las columnas Sweetness, Juiciness y Crunchiness se convierten en etiquetas binarias (1 o 0)\n",
        "fruit = pd.read_csv('apple_quality.csv')\n",
        "fruit['Acidity'] = pd.to_numeric(fruit['Acidity'], errors='coerce')\n",
        "fruit = fruit.dropna()\n",
        "fruit['Sweet'] = np.where(fruit['Sweetness'] > 0.5, 1, 0).astype(float)\n",
        "fruit['Juicy'] = np.where(fruit['Juiciness'] > 0.5, 1, 0).astype(float)\n",
        "fruit['Crunchy'] = np.where(fruit['Crunchiness'] > 0.5, 1, 0).astype(float)\n",
        "features = ['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness']\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(fruit[features])\n",
        "Y = fruit[['Sweet', 'Juicy', 'Crunchy']].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kZ396yzUl6cB"
      },
      "outputs": [],
      "source": [
        "#En esta lista guardamos los nombres de las columnas que serán usadas como entrada para la red.\n",
        "#transforma los valores de las características para que tengan 0 y 1.\n",
        "#X contiene las que serán las entradas de la red\n",
        "#Y contiene las etiquetas binarias que van a ser la salida.\n",
        "features = ['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness']\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(fruit[features])\n",
        "Y = fruit[['Sweet', 'Juicy', 'Crunchy']].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8cKw5Fxwl8iw"
      },
      "outputs": [],
      "source": [
        "#Ponemos los Hiperparametros\n",
        "input_size = X.shape[1]\n",
        "output_size = Y.shape[1]\n",
        "epochs = 3000\n",
        "learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTVkDatSl-VD",
        "outputId": "67a926d0-e598-4d06-9ca5-cd1d5226799f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 0.1991\n",
            "Epoch 100, Loss: 0.1977\n",
            "Epoch 200, Loss: 0.1964\n",
            "Epoch 300, Loss: 0.1951\n",
            "Epoch 400, Loss: 0.1938\n",
            "Epoch 500, Loss: 0.1925\n",
            "Epoch 600, Loss: 0.1912\n",
            "Epoch 700, Loss: 0.1900\n",
            "Epoch 800, Loss: 0.1887\n",
            "Epoch 900, Loss: 0.1875\n",
            "Epoch 1000, Loss: 0.1863\n",
            "Epoch 1100, Loss: 0.1851\n",
            "Epoch 1200, Loss: 0.1839\n",
            "Epoch 1300, Loss: 0.1828\n",
            "Epoch 1400, Loss: 0.1816\n",
            "Epoch 1500, Loss: 0.1805\n",
            "Epoch 1600, Loss: 0.1794\n",
            "Epoch 1700, Loss: 0.1783\n",
            "Epoch 1800, Loss: 0.1772\n",
            "Epoch 1900, Loss: 0.1761\n",
            "Epoch 2000, Loss: 0.1751\n",
            "Epoch 2100, Loss: 0.1740\n",
            "Epoch 2200, Loss: 0.1730\n",
            "Epoch 2300, Loss: 0.1720\n",
            "Epoch 2400, Loss: 0.1710\n",
            "Epoch 2500, Loss: 0.1700\n",
            "Epoch 2600, Loss: 0.1690\n",
            "Epoch 2700, Loss: 0.1681\n",
            "Epoch 2800, Loss: 0.1671\n",
            "Epoch 2900, Loss: 0.1662\n"
          ]
        }
      ],
      "source": [
        "#Aca hacemos entrenar la red neuronal\n",
        "#Inicializa los pesos y el sesgo.\n",
        "#Realiza la propagación hacia adelante y hacia atrás en cada para ajustar los pesos y el sesgo.\n",
        "weights, bias = train(X, Y, input_size, output_size, epochs, learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMNcTomdmAcP",
        "outputId": "b2efdd08-f247-4531-9cec-c08d5a5b3cf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicciones:\n",
            "[[1 1 0]\n",
            " [1 1 1]\n",
            " [0 1 0]\n",
            " ...\n",
            " [0 0 0]\n",
            " [1 1 0]\n",
            " [1 1 0]]\n",
            "Salidas reales:\n",
            "[[1. 1. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 1. 0.]\n",
            " ...\n",
            " [0. 1. 1.]\n",
            " [1. 1. 0.]\n",
            " [0. 1. 0.]]\n",
            "Mean Squared Error: 0.19625\n"
          ]
        }
      ],
      "source": [
        "#Predicciones\n",
        "#uso el modelo entrenado (con los pesos y sesgo ajustados) para hacer predicciones en X\n",
        "predictions = predict(X, weights, bias)\n",
        "print(\"Predicciones:\")\n",
        "print(predictions)\n",
        "\n",
        "#Mostramos las Y para ver  las predicciones y evaluar la funcionalidad de la red.\n",
        "print(\"Salidas reales:\")\n",
        "print(Y)\n",
        "\n",
        "#calculamos el error cuadrático medio entre las salidas reales y las predicciones.\n",
        "#Nos da una idea de cuánto se desvían las predicciones de la red neuronal respecto a las etiquetas reales.\n",
        "mse = mean_squared_error(Y, predictions)\n",
        "print(\"Mean Squared Error:\", mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q34wdOy_pZGo"
      },
      "source": [
        "Nosotras hicimios una red neuronal para clasificar frutas en función de sus características, utilizando un conjunto de datos que incluía atributos como tamaño, peso, dulzura, crujiente y jugosidad. Despues de preparar los datos y normalizar las caracteristicas y poner las etiquetas pudimos hacer que la red aprenda a predecir estas etiquetas a partir de las características, logrando una aproximación efectiva con un error cuadrático medio bajo, lo que indica que la red pudo clasificar correctamente las frutas según sus atributos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
